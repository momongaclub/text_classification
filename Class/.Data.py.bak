import os
import torch
import torchtext
from torchtext.datasets import text_classification

NGRAMS = 2
DATA_NAME = 'AG_NEWS'
DATA_DIR = './.data'


class Text_classification(text_classification.TextClassificationDataset):

    def _setup_datasets(dataset_name, root='.data', ngrams=1, vocab=None, include_unk=False):
        dataset_tar = download_from_url(URLS[dataset_name], root=root)
        extracted_files = extract_archive(dataset_tar)

        print(extracted_files)

        for fname in extracted_files:
            if fname.endswith('train.csv'):
                train_csv_path = fname
            if fname.endswith('test.csv'):
                test_csv_path = fname

        if vocab is None:
            logging.info('Building Vocab based on {}'.format(train_csv_path))
            vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams))
        else:
            if not isinstance(vocab, Vocab):
                raise TypeError("Passed vocabulary is not of type Vocab")
        logging.info('Vocab has {} entries'.format(len(vocab)))
        logging.info('Creating training data')
        train_data, train_labels = _create_data_from_iterator(
            vocab, _csv_iterator(train_csv_path, ngrams, yield_cls=True), include_unk)
        logging.info('Creating testing data')
        test_data, test_labels = _create_data_from_iterator(
            vocab, _csv_iterator(test_csv_path, ngrams, yield_cls=True), include_unk)
        if len(train_labels ^ test_labels) > 0:
            raise ValueError("Training and test labels don't match")
        return (TextClassificationDataset(vocab, train_data, train_labels),
                TextClassificationDataset(vocab, test_data, test_labels))


class Data():

    def __init__(self):
        self.train_dataset = ''
        self.test_dataset = ''

    def load_data(self, data_name):
        if not os.path.isdir(DATA_DIR): #ディレクトリの存在確認
            os.mkdir(DATA_DIR)
        self.train_dataset, self.test_dataset = \
            text_classification.DATASETS[data_name](root=DATA_DIR,
                                                    ngrams=NGRAMS,
                                                    vocab=None)


class Dataset(torch.utils.data.Dataset):


    def __init__(self):
        self.data = []

def main():
    data = Data()
    data.load_data(DATA_NAME)
    print(type(data.train_dataset))
    return


if __name__ == '__main__':
    main()
